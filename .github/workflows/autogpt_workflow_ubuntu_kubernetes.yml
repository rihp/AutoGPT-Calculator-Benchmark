name: AutoGPT Kubernetes Workflow

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout AutoGPT repository
        uses: actions/checkout@v2
        with:
          repository: Significant-Gravitas/Auto-GPT
          ref: v0.2.2
          path: autogpt

      - name: Set up Python 3.10
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'

      - name: Upgrade pip and install dependencies
        working-directory: autogpt
        run: |
          sudo apt-get update && sudo apt-get dist-upgrade
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: setup-docker
        uses: docker-practice/actions-setup-docker@1.0.11

      - name: Ensure Docker is running
        run: |
          docker info

      - name: Configure .env file
        working-directory: autogpt
        run: |
          templateContent=$(cat .env.template)
          apiKeyReplacement=${templateContent/your-openai-api-key/${{ secrets.OPENAI_API_KEY }}}
          configContent=${apiKeyReplacement/EXECUTE_LOCAL_COMMANDS=False/EXECUTE_LOCAL_COMMANDS=True}
          echo "$configContent" > .env

      - name: Create auto-gpt.json file
        working-directory: autogpt
        run: |
          touch auto-gpt.json

      - name: Run AutoGPT command
        working-directory: autogpt
        run: |
          inputSequence=(
            "K8sGPT"
            "an AI assistant that specializes in Kubernetes deployment configuration, providing expert guidance to ensure your containerized applications run smoothly and efficiently."
            "create a kubernetes deploy.yml file, named nginxdeploy, which includes 10 instances of a container called nginx-dep and an image of nginx:1.21.1-alpine with the port TCP 80 defined."
            "Optimize the deployment file to ensure efficient resource utilization and high availability while minimizing downtime."
            "Implement best practices for container security and compliance to minimize risk of breaches and data loss."
            "Troubleshoot any deployment-related issues that may arise and provide actionable recommendations for resolving them promptly."
            ""
            "y -10"
            "n"
          )
          printf '%s\n' "${inputSequence[@]}" | python -m autogpt --gpt3only
          
      - name: Upload deploy.yaml as artifact
        uses: actions/upload-artifact@v2
        working-directory: autogpt
        with:
          name: gpt-k8s-deploy-yaml
          path: auto_gpt_workspace/deploy.yaml

      - name: Set up Kubectl
        uses: azure/setup-kubectl@v1
        with:
          version: 'latest'

      - name: Create dummy kubeconfig
        run: |
          echo "apiVersion: v1" > kubeconfig.yaml
          echo "clusters:" >> kubeconfig.yaml
          echo "- cluster:" >> kubeconfig.yaml
          echo "    server: http://localhost:8080" >> kubeconfig.yaml
          echo "  name: dummy" >> kubeconfig.yaml
          echo "contexts:" >> kubeconfig.yaml
          echo "- context:" >> kubeconfig.yaml
          echo "    cluster: dummy" >> kubeconfig.yaml
          echo "    user: dummy" >> kubeconfig.yaml
          echo "  name: dummy" >> kubeconfig.yaml
          echo "current-context: dummy" >> kubeconfig.yaml
          echo "kind: Config" >> kubeconfig.yaml
          echo "preferences: {}" >> kubeconfig.yaml
          echo "users:" >> kubeconfig.yaml
          echo "- name: dummy" >> kubeconfig.yaml
          echo "  user: {}" >> kubeconfig.yaml

      - name: Display deploy.yaml content
        working-directory: autogpt
        run: |
          cat auto_gpt_workspace/deploy.yaml

      - name: Validate deploy.yaml
        working-directory: autogpt
        run: |
          export KUBECONFIG=kubeconfig.yaml
          kubectl apply --dry-run=client --validate -f deploy.yaml
